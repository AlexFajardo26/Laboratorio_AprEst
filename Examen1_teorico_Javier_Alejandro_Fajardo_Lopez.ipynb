{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 1: Conceptos Teóricos (40 puntos)\n",
    "(5 pts) ¿Cuál es la diferencia entre una regresión lineal simple y una regresión lineal múltiple? Da un ejemplo de cada una.\n",
    "\n",
    "(5 pts) Explica el problema de overfitting y cómo podrías mitigarlo \n",
    "\n",
    "(5 pts) En regresión polinomial, ¿por qué es necesario realizar un análisis de validación cruzada antes de elegir el grado del polinomio?\n",
    "\n",
    "(5 pts) ¿Qué es una prueba de hipótesis en el contexto de regresión lineal? Explica cómo se interpreta el p-value de un coeficiente.\n",
    "\n",
    "(5 pts) ¿Por qué convertir variables categóricas en dummies puede mejorar el desempeño de un modelo? ¿En qué casos podríamos usar una codificación diferente?\n",
    "\n",
    "(5 pts) Explica como se obtienen los coeficientes de una regresión lineal con decenso en gradiente (tanto para lineal como polinomio), me tiene que quedar claro que le entiendes\n",
    "\n",
    "(5 pts) Explica que es el teorema de Frisch-Waugh-Lovell\n",
    "\n",
    "(5 pts) Explica que es K-nearest neighboors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas Sección 1\n",
    "\n",
    "**A**) La diferencia entre una regresión simple y una multiple es que en la regresión lineal simple solo se usa una variable independiente para poder predecir la variable dependiente. En la regresion multiple se pueden usar 2 o más variables independientes para poder predecir. \n",
    "\n",
    "Ejemplo de regresión simple\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1$\n",
    "\n",
    "Ejemplo de la regresión lineal multiple\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1 + B_2 x_2 + ......+ B_n x_n$\n",
    "\n",
    "**B**) El overfitting es cuando tu módelo esta sobreajustado a los valores que esta intentando predecir, empezando a memorizar como es que se van presentando los datos, haciendo ver que es muy bueno el módelo pero en realidad no hará una predicción acertada. La forma de poder mitigarlo es haciendo cross validation, ya que con esto podremos separar nuestros datos en train y test, pudiendo predecir datos que ya tenemos y con esto evaluar el módelo. Penalizar  las betas del módelo también ayuda a eliminarlo, ya sea por Risdge o Lasso. Esto nos ayuda a poder detectar si hay overfitting y eliminarlo para que nuestro módelo final para ahora si predecir sea el mejor. \n",
    "\n",
    "**C**) Como en una regresión polinomial la linea de predicción puede ser curveada, esto permite ajustarse mejor a los datos presentados. Sin embargo, al poderse curvear y ajustar tanto, si no se hace el cross validation, hay riesgo de que exista overfitting, tu módelo empezará a memorizar y no será nada eficaz para poder predecir. \n",
    "\n",
    "**D**)En cuanto a una regresión lineal, una prueba de hipotesis es un método que nos ayuda a entender si una variable es significativa para nuestro módelo de regresión o no. Es decir si esta variable tiene un impacto importante es nuestra regresión. El p-value es la métrica que nos ayuda a saber si la variable es significativa o no. Cuando una variable tiene menos que 5% en el p-value, se dice que es significativa, si este es mayor a 5%, la variable no es significativa y no tiene impacto en la regresión.\n",
    "\n",
    "**E**)Cuando tenemos variables categoricas, los valores dentro de esta, ya sean numeros o palabras son categorias, mismas que ya sea por la palabra o el numero que se le asigno, tienen mayor orden e impacto en nuestro módelo. Si tenemos 2 categorias, la 1 y la 6, la categoria 6 tendrá más peso sobre el módelo porque el número es mayor pero no porque en realidad la categoria lo sea. El hacer dummies permite que todas las categorias tengan el mismo impacto, mejorando considerablemente el módelo. Otro tipo de codificación para variables categoricas sería hacer las variables númericas a categóricas mediante la implementacion de bins o cuartiles. Para el módelo esto puede ser beneficioso ya que si si separamos las variables mediante cuantiles, estos nos pueden servir como categorias. Esto nos es util para descubrir tendencias en nuestras categorias y el impacto que estas pueden tener sobre el módelo.\n",
    "\n",
    "\n",
    "**F**) El decenso en gradiente es un método de optimización mediante el cual se busca minimzar una función actualizando las betas de nuetsro módelo.\n",
    "\n",
    "En este caso, tenemos la función de pérdida:\n",
    "\n",
    "$L = \\frac{1}{2}\\sum(x_1 B_1 - y)^2$\n",
    "\n",
    "Lo que hacemos es actualizar las betas mediante $B_1 = B - \\alpha \\frac{\\partial L}{\\partial B_1}$, donde vamos a restar la beta inicial con una tasa de aprendizaje que nos permitirá no tener un cambio muy grande multiplicada por el gradiente que es una derivada parcial de la beta sobre nuestra función. \n",
    "\n",
    "Esta derivada, dependiendo de donde se encuentre en la gráfica (curva concava hacia arriba), nos da una pendiente positiva o negativa, la cual junto con el signo menos y la tasa de aprendizaje, nos permitira y alternando en la curva hasta que llegemos al punto donde convergen y llegamos al mínimo.\n",
    "\n",
    "Mientras se va haciendo cada una de las iteraciones, las betas se van actualizando hasta que se llegan a una función óptima donde se tienen las betas necesarias para poder minimzar la función de pérdida. \n",
    "\n",
    "La diferencia entre como se obtiene para una regresión lineal y una polinomial es a la hora de hacer las actualizaciones ya que en la lineal cambia el beta inicial y la variable sobre la cual se hace la derivada:\n",
    "\n",
    "\n",
    "$\\beta_0 := \\beta0 - \\frac{\\partial}{\\partial \\beta_0} J(\\beta_0, \\beta_1)$\n",
    "\n",
    "​\n",
    "$\\beta_1 := \\beta_1 - \\frac{\\partial}{\\partial \\beta_1} J(\\beta_0, \\theta_1)$\n",
    "\n",
    "​\n",
    " Mientras que para el polinomial ademas se agrega una variable $x_i$ la cual esta elevada al exponente de la beta que se vaya a actualizar:\n",
    " \n",
    " \n",
    "$\\beta_0 := \\beta_0 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) $\n",
    "\n",
    "\n",
    "$\\beta_1 := \\beta_1 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) x^{(i)}$\n",
    "\n",
    "\n",
    "$\\beta_2 := \\beta_2 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) (x^{(i)})^2$\n",
    "\n",
    "\n",
    "De esta forma se puede diferencias como es que se actualizan las betas tanto en una regresión lineal como para una polinomial.\n",
    "\n",
    "\n",
    "**G**) El teorema de Frisch-Waugh-Lovell nos ayuda a establecer el valor de una beta en nuetsro módelo de regresión. \n",
    "\n",
    "Teniendo un ejemplo de una regresión lineal:\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1 + B_2 x_2 + B_3 x_3$\n",
    "\n",
    "Queremos encontrar el valor que tiene $B_1$\n",
    "\n",
    "Para esto haremos una regresión extra donde solo haremos la predicción con las variables $x_1$ y $x_2$\n",
    "\n",
    "$\\hat{y} = \\Theta_0 + \\Theta_1 x_2 + \\Theta_2 x_3$\n",
    "\n",
    "Después de esto sacaremos los residuales de $y$ contra nuestra $\\hat{y}$ de nuestra segunda regresión\n",
    "\n",
    "$y - \\hat{y} = \\text{residuales } y$\n",
    "\n",
    "Estos residuales se entienden como todo aquello que la variable $x_2 y $x_3$ no pudieron explicar de $y$\n",
    "\n",
    "Después hacemos una regresión intentando predecir $x_1$ con las variables $x_2 y $x_3$ \n",
    "\n",
    "$\\hat{x}_1 = \\delta_0 + \\delta_2 x_2 + \\delta_3 x_3$\n",
    "\n",
    "Tras esto sacaremos los residuales de $x1$ contra $\\hat{x}_1$\n",
    "\n",
    "$x_1 - \\hat{x}_1 = \\text{residuales } x$\n",
    "\n",
    "Estos residuales se entienden como todo aquellos que $x_2$ y $x_3$ no lograron explicar de $x_1$.\n",
    "\n",
    "Por último regresamos los residuales de y con los residuales de $x_1$\n",
    "\n",
    "$y - \\hat{y} = B_1 (x_1 - \\hat{x}_1)$\n",
    "\n",
    "Con esto obtenemos que el coeficiente de $B_1$ es igual al de nuestro módelo de regresión final, encontrando el efecto causal que tiene la variable $x_1$ sobre nuestro módelo. \n",
    "\n",
    "Esto nos ayuda a entender que para saber el efecto de una variable no es necesario poner todas las variables sobre el módelo de regresión.\n",
    "\n",
    "\n",
    "**H**) El modelo KNN es un algoritmo usado para clasificación o regresion. Lo que hace este módelo es elegir el numero de K vecinos (datos ya presentados)  más cercanos dependiendo de las distancia euclidiana que tiene con el valor que quieres predecir, y teniendo en cuenta el valor de estos K vecinos, se saca el promedio de los valores de estos  y este promedio es el valor de nuestra predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 2 (20 puntos)\n",
    "\n",
    "(10 pts) Dado el siguiente dataset de casas:\n",
    "\n",
    "```\n",
    "data = pd.DataFrame({\n",
    "    \"Tamaño_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]  })\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "a) Ajusta una regresión lineal para predecir el precio en función del tamaño y número de habitaciones, dime el R2 y coeficientes.\n",
    "\n",
    "\n",
    "b) Imagina que el coeficiente de Tamaño es 2.5 y el coeficiente de Habitaciones es 20, ¿cómo interpretarías estos valores?  \n",
    "\n",
    "(20 pts) Imagina que entrenas un modelo de regresión polinomial de grado 5 y obtienes un 𝑅2 de 0.98 en el conjunto de entrenamiento y 0.65 en el conjunto de prueba.\n",
    "\n",
    "- a) ¿Qué problema podrías estar enfrentando?\n",
    "- b) ¿Cómo lo solucionarías sin reducir demasiado la capacidad del modelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas sección 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tamaño_m2</th>\n",
       "      <th>Habitaciones</th>\n",
       "      <th>Precio_1000s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tamaño_m2  Habitaciones  Precio_1000s\n",
       "0         50             1           110\n",
       "1         80             2           170\n",
       "2        120             3           250\n",
       "3        200             4           400\n",
       "4        150             3           270\n",
       "5         90             2           200\n",
       "6        175             3           330\n",
       "7         60             1           190\n",
       "8        220             5           600\n",
       "9        130             3           380"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Tamaño_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]  })\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Precio_1000s   R-squared:                       0.866\n",
      "Model:                            OLS   Adj. R-squared:                  0.828\n",
      "Method:                 Least Squares   F-statistic:                     22.66\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           0.000876\n",
      "Time:                        21:09:33   Log-Likelihood:                -53.255\n",
      "No. Observations:                  10   AIC:                             112.5\n",
      "Df Residuals:                       7   BIC:                             113.4\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -0.0869     47.302     -0.002      0.999    -111.939     111.765\n",
      "Habitaciones    86.3339     55.729      1.549      0.165     -45.443     218.111\n",
      "Tamaño_m2        0.4469      1.191      0.375      0.719      -2.370       3.264\n",
      "==============================================================================\n",
      "Omnibus:                        1.959   Durbin-Watson:                   0.504\n",
      "Prob(Omnibus):                  0.375   Jarque-Bera (JB):                1.018\n",
      "Skew:                           0.430   Prob(JB):                        0.601\n",
      "Kurtosis:                       1.695   Cond. No.                         418.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('Precio_1000s ~ Habitaciones + Tamaño_m2 ', data = data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta regresión lineal múltiple obtuvimos un R2 de 0.866 y los coeficientes fueron 0.44 para la variavle Tamaño_m2 y 86.33 para la variable Habitaciones, teniendo un gran impacto el numero de habitaciones en nuestro módelo. Además, tenemos una constante con un valor de -0.0869."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuvieramos que los coeficientes de el Tamaño_m2 es de 2.5 y el de Habitaciones es de 20, tenemos una interpretación muy parecida a la de la regresión normal, ya que el coeficiente de Habitaciones es mucho más alto que el de Tamaño_m2, entendindo que las habitaciones tienen un amyor impacto sobre el precio de las casas que el impacto que tiene el tamaño. A pesar de esto, si se puede decir que es menor la diferencia entre el impacto de habitaciones con el de tamaño aquí que en la regresión original, ya que habitaciones paso de tener 80 a 20, lo cual reduce su impacto de forma considerable en el módelo y Tamaño aumenta de 0.44 a 2.5, elevando un poco el efecto que tiene sobre nuestra regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) El problema que podriamos estar teniendo es que hay overfitting, ya que el módelo puede estar memorizando los datos y no prediciendo como tal. \n",
    "\n",
    "b) Para poder eliminar este tipo de problema lo que podemos usar es la regularización Ridge o la regularización Lasso, que permite que las betas de nuestra regresión se vean penalizadas ya sea elevandolas al cuadrado mediante Ridge o con valor absoluto con Lasso. Esto hará que variables que no sea signifcativas al modelo tengan mucho impacto sobre este ya sea dandoles menos peso a sus betas o incluso llegandolas a eliminar con Lasso. Esto nos ayudará a tener un mejor módelo que no haga overfitting y tenga mejor desempeño en nuestras predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sección 3: Implementación de Código (40 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1- En el dataset Advertising.csv estan las ventas de una empresa y hay 3 canales de distribuición:\n",
    "    \n",
    "- radio\n",
    "- Televisión\n",
    "- Periodico\n",
    "\n",
    "\n",
    "La empresa quiere simplificar su operción y eliminar aquellos canales que no traen ventas.\n",
    "\n",
    "Dime que canal o canales no sirven con una prueba de hipotesis y una regresión\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           1.58e-96\n",
      "Time:                        21:18:17   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "prueba_hipotesis = smf.ols('sales ~ TV + radio + newspaper', data=df).fit()\n",
    "print(prueba_hipotesis.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usamos las 3 variables, obtenemos una regresión con un R2 de 0.897, obteniendo un buen módelo para poder hacer las predicciones. \n",
    "\n",
    "También con esto podemos ver que el p-value de las varibles son 0 tanto para TV como para radio, pero para el periodico es de 0.860. Este p-value tan alto nos indica que esta variable en realidad no es significante para nuestro módelo de regresión. Con esto entendido, se podría decir que para simplificar la operación de la empresa, debería eliminar el canal de periodico, ya que no es significativo y con los otros dos se podrían obtener grandes resultados. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
