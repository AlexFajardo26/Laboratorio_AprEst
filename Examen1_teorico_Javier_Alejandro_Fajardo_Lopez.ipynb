{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Secci贸n 1: Conceptos Te贸ricos (40 puntos)\n",
    "(5 pts) 驴Cu谩l es la diferencia entre una regresi贸n lineal simple y una regresi贸n lineal m煤ltiple? Da un ejemplo de cada una.\n",
    "\n",
    "(5 pts) Explica el problema de overfitting y c贸mo podr铆as mitigarlo \n",
    "\n",
    "(5 pts) En regresi贸n polinomial, 驴por qu茅 es necesario realizar un an谩lisis de validaci贸n cruzada antes de elegir el grado del polinomio?\n",
    "\n",
    "(5 pts) 驴Qu茅 es una prueba de hip贸tesis en el contexto de regresi贸n lineal? Explica c贸mo se interpreta el p-value de un coeficiente.\n",
    "\n",
    "(5 pts) 驴Por qu茅 convertir variables categ贸ricas en dummies puede mejorar el desempe帽o de un modelo? 驴En qu茅 casos podr铆amos usar una codificaci贸n diferente?\n",
    "\n",
    "(5 pts) Explica como se obtienen los coeficientes de una regresi贸n lineal con decenso en gradiente (tanto para lineal como polinomio), me tiene que quedar claro que le entiendes\n",
    "\n",
    "(5 pts) Explica que es el teorema de Frisch-Waugh-Lovell\n",
    "\n",
    "(5 pts) Explica que es K-nearest neighboors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas Secci贸n 1\n",
    "\n",
    "**A**) La diferencia entre una regresi贸n simple y una multiple es que en la regresi贸n lineal simple solo se usa una variable independiente para poder predecir la variable dependiente. En la regresion multiple se pueden usar 2 o m谩s variables independientes para poder predecir. \n",
    "\n",
    "Ejemplo de regresi贸n simple\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1$\n",
    "\n",
    "Ejemplo de la regresi贸n lineal multiple\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1 + B_2 x_2 + ......+ B_n x_n$\n",
    "\n",
    "**B**) El overfitting es cuando tu m贸delo esta sobreajustado a los valores que esta intentando predecir, empezando a memorizar como es que se van presentando los datos, haciendo ver que es muy bueno el m贸delo pero en realidad no har谩 una predicci贸n acertada. La forma de poder mitigarlo es haciendo cross validation, ya que con esto podremos separar nuestros datos en train y test, pudiendo predecir datos que ya tenemos y con esto evaluar el m贸delo. Penalizar  las betas del m贸delo tambi茅n ayuda a eliminarlo, ya sea por Risdge o Lasso. Esto nos ayuda a poder detectar si hay overfitting y eliminarlo para que nuestro m贸delo final para ahora si predecir sea el mejor. \n",
    "\n",
    "**C**) Como en una regresi贸n polinomial la linea de predicci贸n puede ser curveada, esto permite ajustarse mejor a los datos presentados. Sin embargo, al poderse curvear y ajustar tanto, si no se hace el cross validation, hay riesgo de que exista overfitting, tu m贸delo empezar谩 a memorizar y no ser谩 nada eficaz para poder predecir. \n",
    "\n",
    "**D**)En cuanto a una regresi贸n lineal, una prueba de hipotesis es un m茅todo que nos ayuda a entender si una variable es significativa para nuestro m贸delo de regresi贸n o no. Es decir si esta variable tiene un impacto importante es nuestra regresi贸n. El p-value es la m茅trica que nos ayuda a saber si la variable es significativa o no. Cuando una variable tiene menos que 5% en el p-value, se dice que es significativa, si este es mayor a 5%, la variable no es significativa y no tiene impacto en la regresi贸n.\n",
    "\n",
    "**E**)Cuando tenemos variables categoricas, los valores dentro de esta, ya sean numeros o palabras son categorias, mismas que ya sea por la palabra o el numero que se le asigno, tienen mayor orden e impacto en nuestro m贸delo. Si tenemos 2 categorias, la 1 y la 6, la categoria 6 tendr谩 m谩s peso sobre el m贸delo porque el n煤mero es mayor pero no porque en realidad la categoria lo sea. El hacer dummies permite que todas las categorias tengan el mismo impacto, mejorando considerablemente el m贸delo. Otro tipo de codificaci贸n para variables categoricas ser铆a hacer las variables n煤mericas a categ贸ricas mediante la implementacion de bins o cuartiles. Para el m贸delo esto puede ser beneficioso ya que si si separamos las variables mediante cuantiles, estos nos pueden servir como categorias. Esto nos es util para descubrir tendencias en nuestras categorias y el impacto que estas pueden tener sobre el m贸delo.\n",
    "\n",
    "\n",
    "**F**) El decenso en gradiente es un m茅todo de optimizaci贸n mediante el cual se busca minimzar una funci贸n actualizando las betas de nuetsro m贸delo.\n",
    "\n",
    "En este caso, tenemos la funci贸n de p茅rdida:\n",
    "\n",
    "$L = \\frac{1}{2}\\sum(x_1 B_1 - y)^2$\n",
    "\n",
    "Lo que hacemos es actualizar las betas mediante $B_1 = B - \\alpha \\frac{\\partial L}{\\partial B_1}$, donde vamos a restar la beta inicial con una tasa de aprendizaje que nos permitir谩 no tener un cambio muy grande multiplicada por el gradiente que es una derivada parcial de la beta sobre nuestra funci贸n. \n",
    "\n",
    "Esta derivada, dependiendo de donde se encuentre en la gr谩fica (curva concava hacia arriba), nos da una pendiente positiva o negativa, la cual junto con el signo menos y la tasa de aprendizaje, nos permitira y alternando en la curva hasta que llegemos al punto donde convergen y llegamos al m铆nimo.\n",
    "\n",
    "Mientras se va haciendo cada una de las iteraciones, las betas se van actualizando hasta que se llegan a una funci贸n 贸ptima donde se tienen las betas necesarias para poder minimzar la funci贸n de p茅rdida. \n",
    "\n",
    "La diferencia entre como se obtiene para una regresi贸n lineal y una polinomial es a la hora de hacer las actualizaciones ya que en la lineal cambia el beta inicial y la variable sobre la cual se hace la derivada:\n",
    "\n",
    "\n",
    "$\\beta_0 := \\beta0 - \\frac{\\partial}{\\partial \\beta_0} J(\\beta_0, \\beta_1)$\n",
    "\n",
    "\n",
    "$\\beta_1 := \\beta_1 - \\frac{\\partial}{\\partial \\beta_1} J(\\beta_0, \\theta_1)$\n",
    "\n",
    "\n",
    " Mientras que para el polinomial ademas se agrega una variable $x_i$ la cual esta elevada al exponente de la beta que se vaya a actualizar:\n",
    " \n",
    " \n",
    "$\\beta_0 := \\beta_0 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) $\n",
    "\n",
    "\n",
    "$\\beta_1 := \\beta_1 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) x^{(i)}$\n",
    "\n",
    "\n",
    "$\\beta_2 := \\beta_2 - \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\hat{y}^{(i)} - y^{(i)} \\right) (x^{(i)})^2$\n",
    "\n",
    "\n",
    "De esta forma se puede diferencias como es que se actualizan las betas tanto en una regresi贸n lineal como para una polinomial.\n",
    "\n",
    "\n",
    "**G**) El teorema de Frisch-Waugh-Lovell nos ayuda a establecer el valor de una beta en nuetsro m贸delo de regresi贸n. \n",
    "\n",
    "Teniendo un ejemplo de una regresi贸n lineal:\n",
    "\n",
    "$\\hat{y} = B_0 + B_1 x_1 + B_2 x_2 + B_3 x_3$\n",
    "\n",
    "Queremos encontrar el valor que tiene $B_1$\n",
    "\n",
    "Para esto haremos una regresi贸n extra donde solo haremos la predicci贸n con las variables $x_1$ y $x_2$\n",
    "\n",
    "$\\hat{y} = \\Theta_0 + \\Theta_1 x_2 + \\Theta_2 x_3$\n",
    "\n",
    "Despu茅s de esto sacaremos los residuales de $y$ contra nuestra $\\hat{y}$ de nuestra segunda regresi贸n\n",
    "\n",
    "$y - \\hat{y} = \\text{residuales } y$\n",
    "\n",
    "Estos residuales se entienden como todo aquello que la variable $x_2 y $x_3$ no pudieron explicar de $y$\n",
    "\n",
    "Despu茅s hacemos una regresi贸n intentando predecir $x_1$ con las variables $x_2 y $x_3$ \n",
    "\n",
    "$\\hat{x}_1 = \\delta_0 + \\delta_2 x_2 + \\delta_3 x_3$\n",
    "\n",
    "Tras esto sacaremos los residuales de $x1$ contra $\\hat{x}_1$\n",
    "\n",
    "$x_1 - \\hat{x}_1 = \\text{residuales } x$\n",
    "\n",
    "Estos residuales se entienden como todo aquellos que $x_2$ y $x_3$ no lograron explicar de $x_1$.\n",
    "\n",
    "Por 煤ltimo regresamos los residuales de y con los residuales de $x_1$\n",
    "\n",
    "$y - \\hat{y} = B_1 (x_1 - \\hat{x}_1)$\n",
    "\n",
    "Con esto obtenemos que el coeficiente de $B_1$ es igual al de nuestro m贸delo de regresi贸n final, encontrando el efecto causal que tiene la variable $x_1$ sobre nuestro m贸delo. \n",
    "\n",
    "Esto nos ayuda a entender que para saber el efecto de una variable no es necesario poner todas las variables sobre el m贸delo de regresi贸n.\n",
    "\n",
    "\n",
    "**H**) El modelo KNN es un algoritmo usado para clasificaci贸n o regresion. Lo que hace este m贸delo es elegir el numero de K vecinos (datos ya presentados)  m谩s cercanos dependiendo de las distancia euclidiana que tiene con el valor que quieres predecir, y teniendo en cuenta el valor de estos K vecinos, se saca el promedio de los valores de estos  y este promedio es el valor de nuestra predicci贸n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Secci贸n 2 (20 puntos)\n",
    "\n",
    "(10 pts) Dado el siguiente dataset de casas:\n",
    "\n",
    "```\n",
    "data = pd.DataFrame({\n",
    "    \"Tama帽o_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]  })\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "a) Ajusta una regresi贸n lineal para predecir el precio en funci贸n del tama帽o y n煤mero de habitaciones, dime el R2 y coeficientes.\n",
    "\n",
    "\n",
    "b) Imagina que el coeficiente de Tama帽o es 2.5 y el coeficiente de Habitaciones es 20, 驴c贸mo interpretar铆as estos valores?  \n",
    "\n",
    "(20 pts) Imagina que entrenas un modelo de regresi贸n polinomial de grado 5 y obtienes un 2 de 0.98 en el conjunto de entrenamiento y 0.65 en el conjunto de prueba.\n",
    "\n",
    "- a) 驴Qu茅 problema podr铆as estar enfrentando?\n",
    "- b) 驴C贸mo lo solucionar铆as sin reducir demasiado la capacidad del modelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas secci贸n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tama帽o_m2</th>\n",
       "      <th>Habitaciones</th>\n",
       "      <th>Precio_1000s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tama帽o_m2  Habitaciones  Precio_1000s\n",
       "0         50             1           110\n",
       "1         80             2           170\n",
       "2        120             3           250\n",
       "3        200             4           400\n",
       "4        150             3           270\n",
       "5         90             2           200\n",
       "6        175             3           330\n",
       "7         60             1           190\n",
       "8        220             5           600\n",
       "9        130             3           380"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Tama帽o_m2\": [50, 80, 120, 200, 150, 90, 175, 60, 220, 130],\n",
    "    \"Habitaciones\": [1, 2, 3, 4, 3, 2, 3, 1, 5, 3],\n",
    "    \"Precio_1000s\": [110, 170, 250, 400, 270, 200, 330, 190, 600, 380]  })\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Precio_1000s   R-squared:                       0.866\n",
      "Model:                            OLS   Adj. R-squared:                  0.828\n",
      "Method:                 Least Squares   F-statistic:                     22.66\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           0.000876\n",
      "Time:                        21:09:33   Log-Likelihood:                -53.255\n",
      "No. Observations:                  10   AIC:                             112.5\n",
      "Df Residuals:                       7   BIC:                             113.4\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -0.0869     47.302     -0.002      0.999    -111.939     111.765\n",
      "Habitaciones    86.3339     55.729      1.549      0.165     -45.443     218.111\n",
      "Tama帽o_m2        0.4469      1.191      0.375      0.719      -2.370       3.264\n",
      "==============================================================================\n",
      "Omnibus:                        1.959   Durbin-Watson:                   0.504\n",
      "Prob(Omnibus):                  0.375   Jarque-Bera (JB):                1.018\n",
      "Skew:                           0.430   Prob(JB):                        0.601\n",
      "Kurtosis:                       1.695   Cond. No.                         418.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols('Precio_1000s ~ Habitaciones + Tama帽o_m2 ', data = data).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta regresi贸n lineal m煤ltiple obtuvimos un R2 de 0.866 y los coeficientes fueron 0.44 para la variavle Tama帽o_m2 y 86.33 para la variable Habitaciones, teniendo un gran impacto el numero de habitaciones en nuestro m贸delo. Adem谩s, tenemos una constante con un valor de -0.0869."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuvieramos que los coeficientes de el Tama帽o_m2 es de 2.5 y el de Habitaciones es de 20, tenemos una interpretaci贸n muy parecida a la de la regresi贸n normal, ya que el coeficiente de Habitaciones es mucho m谩s alto que el de Tama帽o_m2, entendindo que las habitaciones tienen un amyor impacto sobre el precio de las casas que el impacto que tiene el tama帽o. A pesar de esto, si se puede decir que es menor la diferencia entre el impacto de habitaciones con el de tama帽o aqu铆 que en la regresi贸n original, ya que habitaciones paso de tener 80 a 20, lo cual reduce su impacto de forma considerable en el m贸delo y Tama帽o aumenta de 0.44 a 2.5, elevando un poco el efecto que tiene sobre nuestra regresi贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) El problema que podriamos estar teniendo es que hay overfitting, ya que el m贸delo puede estar memorizando los datos y no prediciendo como tal. \n",
    "\n",
    "b) Para poder eliminar este tipo de problema lo que podemos usar es la regularizaci贸n Ridge o la regularizaci贸n Lasso, que permite que las betas de nuestra regresi贸n se vean penalizadas ya sea elevandolas al cuadrado mediante Ridge o con valor absoluto con Lasso. Esto har谩 que variables que no sea signifcativas al modelo tengan mucho impacto sobre este ya sea dandoles menos peso a sus betas o incluso llegandolas a eliminar con Lasso. Esto nos ayudar谩 a tener un mejor m贸delo que no haga overfitting y tenga mejor desempe帽o en nuestras predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Secci贸n 3: Implementaci贸n de C贸digo (40 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1- En el dataset Advertising.csv estan las ventas de una empresa y hay 3 canales de distribuici贸n:\n",
    "    \n",
    "- radio\n",
    "- Televisi贸n\n",
    "- Periodico\n",
    "\n",
    "\n",
    "La empresa quiere simplificar su operci贸n y eliminar aquellos canales que no traen ventas.\n",
    "\n",
    "Dime que canal o canales no sirven con una prueba de hipotesis y una regresi贸n\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Tue, 18 Feb 2025   Prob (F-statistic):           1.58e-96\n",
      "Time:                        21:18:17   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "prueba_hipotesis = smf.ols('sales ~ TV + radio + newspaper', data=df).fit()\n",
    "print(prueba_hipotesis.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usamos las 3 variables, obtenemos una regresi贸n con un R2 de 0.897, obteniendo un buen m贸delo para poder hacer las predicciones. \n",
    "\n",
    "Tambi茅n con esto podemos ver que el p-value de las varibles son 0 tanto para TV como para radio, pero para el periodico es de 0.860. Este p-value tan alto nos indica que esta variable en realidad no es significante para nuestro m贸delo de regresi贸n. Con esto entendido, se podr铆a decir que para simplificar la operaci贸n de la empresa, deber铆a eliminar el canal de periodico, ya que no es significativo y con los otros dos se podr铆an obtener grandes resultados. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
