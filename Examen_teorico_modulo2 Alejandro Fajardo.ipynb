{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "# Examen modulo 2\n",
    "\n",
    "\n",
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts)** Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?  \n",
    "\n",
    "2. **(10 pts)** Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca  \n",
    "\n",
    "3. **(10 pts)** Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto   \n",
    "\n",
    "\n",
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts)** Define la **curva ROC** y el AUC. ¿Qué tiene de especial\n",
    "\n",
    "8. **(5 pts)** Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal  \n",
    "\n",
    "9. **(5 pts)** Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación.  \n",
    "\n",
    "10. **(5 pts)** Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?\n",
    "\n",
    "\n",
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts)** ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)\n",
    "\n",
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts)** ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno \n",
    "\n",
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts)** Explica que es una red neuronal, que hace, como funciona, etc.   \n",
    " \n",
    "14. **(5 pts)** ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales?  \n",
    "\n",
    "15. **(5 pts)** A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal  \n",
    "\n",
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts)** Explica que es softmax, para que sirve y como se calcula\n",
    "\n",
    "\n",
    "\n",
    "## **Puntaje Total: 100 puntos**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa334d",
   "metadata": {},
   "source": [
    "## Sección 1\n",
    "1. La regresión logptica lineal es aquella donde se asumen que la relación que tienen las variables es de forma lineal, reealizando una clasificacion de los datos de forma mucho más sencila. Por otro lado, la regresión logística polinomial es aquella donde no se asume que la relación de los datos es lineal, por lo tanto se pueden realizar otro tipo de combinaciones, resultando en una predicción un poco más compleja que la lieal incluso puiendo tener regresiones logiticas polinimiales de diferentes grados. A pesar de que pueden tener un ajuste mejor a datos no tan complejos, no siempre resultando en el mejor de los modelos, esto dependerá de la relación que puedan tener las variables y la calidad de los datos que sean presentados. \n",
    "\n",
    "2. Para hacer una regresión logística podemos utilizar la máxima verosimilitud y el descenso en gradiente para poder encontrar la mejor predicción posible. Esto se harpia de la siguiente forma:\n",
    "\n",
    "    Siguiendo el supuesto de que en la regresión logística $y_i$ sigue una distribución de Bernoulli, podemos obtener nuestra función de verosimilitud que es:  \n",
    "\n",
    "    $$\n",
    "    L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "    $$\n",
    "\n",
    "    A esta se le saca el logaritmo para poder hacer de la multiplicación de probabilidades a una sumatoria de los logaritmos y que sean más faciles los calculos.\n",
    "\n",
    "    $$\n",
    "    \\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "    $$\n",
    "\n",
    "    Como estamos buscando el mejor resultado, estimaremos theta maximizando la función de verosimilitud, para luego aplicar el descenso en gradiente y encontrar el mejor resultado\n",
    "\n",
    "    $$\n",
    "    J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "    $$\n",
    "\n",
    "    Tras obtener la maxima verosimulitud, usamos el descenso en gradiente, para que las thetas vayan modificandoe y ajustandose cada vez más. Esto se logra calculando la derivada parcial y usando una tasa de aprendizaje que hará que el cambió no sea tan grande. Este proceso se repite hasta que logra converger y se obtiene el resultado óptimo. \n",
    "    $$\n",
    "    \\theta_j := \\theta_j + \\alpha \\frac{\\partial J}{\\partial \\theta_j}\n",
    "    $$\n",
    "\n",
    "\n",
    "    $$\n",
    "    \\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\theta_j := \\theta_j + \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "    $$\n",
    "\n",
    "    Es importante mencionar que aquí el descenso en gradiente puede ser llamada ascenso en gradiente debido a la forma que tiene la grafica de la función de maxima verosimilitud, siendo una curva que crece y luego vuleve a caer, entendiendo que el gradiente empezará desde los puntos más bajos hasta que logre alcanzar el maximo en la punta de la gráfica. De esta forma usando la función de versomilitud y el descenso en gradiente se puede obtener el modelo de una regresión logística.\n",
    "\n",
    "\n",
    "\n",
    "3. Los odds son la probabilidad de ganar entre la probabilidad de perder. En otras palabras, es la probabilidad de que suceda un evento en especifico entre la probabildad de que ese no suceda. Un ejemplo es si mi equipo gana 1 a 4, el odd sería $\\frac{1}{4}$\n",
    "\n",
    "    Para comprobar esto tenemos que la probabilidad de ganar esn este caso sería:\n",
    "\n",
    "    $$\\frac{1}{1+4} = 0.2$$\n",
    "\n",
    "    La probabilidad de perder sería:\n",
    "\n",
    "    $$\\frac{1}{1+4} = 0.8$$\n",
    "\n",
    "    Si dividimos la probabilidad de ganar entre la de perder obetenemos\n",
    "\n",
    "    $$\\frac{0.2}{0.8} = \\frac{1}{4}$$\n",
    "\n",
    "    Con lo cual se comprueba el concepto de odds.\n",
    "\n",
    "    Si lo ponemos como formula general tenemos que odds $\\frac{p}{1-p}$ donde $p$ es la probabilidad de ganar (pase el evento) y $1-p$ la probabilidad de perder (no pase el evento).\n",
    "\n",
    "    Como los odds no son datos tan estabilizados y sigien un comportamiento exponencial, se utiliza el logaritmo para estabilizarlos y hacerlos más lineales, de esta forma es mas facil poder usarlos en la regresión logística. La fórmula de esto sería $ln (\\frac{p}{1-p})$. De esta forma se obtiene lo que es el concepto de log-odds.\n",
    "\n",
    "    En la regresión logistica los log-odds son parte fundamental de todo el modelo, ya que ayudan a calcular las probabilidades para poder realizar la clasificación que se busca. La razón por la que se utiliazn los log-odds en la regresión logistica y no las probabilidades, es que el logartimo hace que tengan una tendencia más sencilla de poder usar y aplicar, como lo puede ser un comportamiento más lineal.\n",
    "\n",
    "\n",
    "    Este se hace primero calculando los log-odds con los coeficientes de las variables y las caracteristicas de un sujeto aleatorio.\n",
    "\n",
    "    $$\n",
    "    z = \\beta^T X\n",
    "    $$\n",
    "\n",
    "    Después se calcula la probabilidad para poder hacer nuestra predicción usando los log-odds\n",
    "\n",
    "    $$\n",
    "    p=\\frac{1}{1+e^{-z}}\n",
    "    $$\n",
    "\n",
    "    De esta manera usamos log-odds para poder predecir con la regresión logistica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529dafa",
   "metadata": {},
   "source": [
    "## Sección 2\n",
    "1.-  La curva ROC es el gráfico que se obtiene con las matrices de confusión hechas por la regresión logística, dependiendo de la sensitvity y la specificity es cómo se va creando la curva ROC. Esta curva puede ser interpretada mediante el AUC, que es el area bajo la curva. Esta métrica nos ayuda a entender cual de los modelos que fueron graficados con ROC es mejor, siendo el que tenga más área el mejor de esos. \n",
    "\n",
    "El AUC también puede ser explicado como si tu eligieras a dos personas al azar, una de la clase con  numero  1 de tus datos y otra de la clase con numero 0. El AUC es la probabilidad de que la predicción que tiene la clase 1 sea mayor a la predicción que tiene la clase 0.\n",
    "\n",
    "2.- La diagonal de la curva ROC es la parte donde el modelo no logra predecir nada, ya que es donde se unen los puntos de las regresiones logisticas donde se logra predecir bien una clase, pero la otra esta toda clasificada incorrectamente, teniendo una mitad de probabilidad que haga una clasificación correcta o no. Es por eso que se trata siempre de que los modelos esten muy alejados de la linea central, indicando que son buenos modelos para predecir.\n",
    "\n",
    "3.- Si el AUc nos marca que tenemos un score de 0.85 o 85%, esto nos indica que el modelo tiene la capacidad de predecir  con un 85% de probabilidad que la predicción de de la clase 1 sea mayor a la clasificaciónde la clase 0.\n",
    "\n",
    "4.- Si tenemos que un modelo tiene un accuracy de 0.99 pero un AUC de 0.5, quiere decir que aunque se puede estar ajustando bien a los datos, en realidad no esta realizando una clasificación correcta, ya que nos indica que puede tener un 50% de probabilidad de que esta sea correta o no. Este tipo de comportaminetos donde a clasificación nos sea muy buena a comparación de el accuracy es que los datos que se presentaron tengan ciertas desproporciones creando esta situación donde parezca que se tiene una buena predicción pero en realidad no se tenga noción de como clasificar essa predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62654d7d",
   "metadata": {},
   "source": [
    "## Sección 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1031e83",
   "metadata": {},
   "source": [
    "El analisis del discriminante lineal es un modelo el cual mediante las probabilidades de que los datos sean pertencientes a las clases dadas, va a predecir la probabilidad de que un nuevo dato u objeto pertenzca a una de las clases dadas. Este modelo es óptimo para cuando los datos que se te presenten cumplan con el supuesto de que siguen el comportamineto de una distribución normal.  \n",
    "\n",
    "Para hacer el modelo, primero, asumimos que los datos siguen una distribución normal multivariada. Después de esto, se calcula la probabilidad de que los datos sean pertencientes a las clases que en este caso son representadas por $k$.\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Dados los datos y sabiendo las probabilidades, usamos el Teorema de Bayes para poder calcular la probabilidad de que un nuevo dato u objeto sea pertenciente a una de las clase $k$\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Por último, con los resultados arrojados se elije la clase que tenga la probabilidad más alta y este dato serpa clasificado como pertenciente a esa clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd0ee27",
   "metadata": {},
   "source": [
    "## Sección 4\n",
    "\n",
    "El grid search es cuando se usan todos los datos que se estan presentando para el modelado que se esta implementando. Esto nos ayuda a tener un mejor conocimeinto de todos los datos, ya que contaremos con todo el historial, todas las combianciones hechas y se puede hacer una predicción con más noción de lo que suceden en tus datos. \n",
    "\n",
    "Por otro lado el random search es realizar la predicción con un modelo, pero en vez de usar todos los datos históricos, se usan solo cierta cantidad de datos de forma aleatoria, de esta forma solo se basan en una muestra de los datos, siendo una menor cantidad de combinaciones.\n",
    "\n",
    "La principal diferencia entre estos dos es la cantidad de datos que se utilizan para el modelado, ya que como se epxlico arriba, una usa todos los datos posibles y otra solo agarra una muestra de los datos. Siguiendo esto, el grid search es un modelo recomendable para cuando no se tiene una gran cantidad de datos historicos y no costará hacer un modelo que realice todas las combinaciones posibles con los datos presentados. Si el caso fuera que se tiene muchos datos que haga casi imposible la tarea de relizar todas las combinaciones, ahí es donde el random search es útil, ya que solo tomara una cantidad aleatoria de datos para realizar las combinaciones y al ser aleatoria, el modelo puede tener una buena predicción sin basarse en tendecias erroneas que los datos pueden presentar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa67ed",
   "metadata": {},
   "source": [
    "## Sección 5\n",
    "\n",
    "1.- Una red neuronal es un  modelo de predicción en el cual se entrenan y transforman cierta cantidad de datos mediante capas y neuronas para poder llegar a una predicción. La red neuronal empieza por la primera capa, donde se introducen todos los datos que serán utilizados para la predicción. Despues de esto, los datos son pasados a la primera capa oculta , dodne se multiplican por pesos asignados  y usando una fucnión de activación, los datos presentaran transformaciones, las cuales irán ajustando los datos para poder temer una predicción buena. Este proceso de la red neuronal se repite durante todas las capas ocualtas que existan dentro de la red neuronal, siguiendo el mismo proceso de tranformación, cada capa con su funci´pn de activación propia. Por ultimol se obteien un resultado, el cual sería la predicción que hizo este modelo. A todo este proceso se le conoce como Forwrad propagation. \n",
    "\n",
    "2.- Después de realizarse el forward propagation se realiza un proceso nuevo llamada Backpropagation, el cual consiste en una vez que se tengan los datos de la predicción, ahora se usarán esos mismos como datos de entrada de la red neuronal, para que puedan sufrir el mismo proceso de tranformación mediante las capas ocultas y se llegue a una nueva predicción. Este proceso de Backpropgation se realiza muchas veces hasta que la predicción logré ser la más óptima en el modelo. Esto es por el cual el modelo va calculando el error de las predicciones y va aprendiendo, siendo cada proceso de Forward propagation y Backpropagtion más preciso hasta llegar al óptimo. \n",
    "\n",
    "3.-Los coeficientes de la red neuronal se obtiene restando los pesos y el sesgo a la mulplicación de la derivada parcial por una tasa de aprendizaje asignada.\n",
    "   $$\n",
    "   W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "   $$\n",
    "   $$\n",
    "   b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "   $$\n",
    "\n",
    "Esto se reliza mediante el Back propagation, donde cada vez se ajustan más los pesos, el error va disminuyendo, y los coeficientes se van actualizando, hasta que se obtienen los mejores coeficientes, el menor error con esto la mejor predicción. \n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f57076",
   "metadata": {},
   "source": [
    "## Sección 6 \n",
    "\n",
    "Utilizamos la función Softmax cuando tenemos que decidir como realizar la clasificación entre muchas clases, es decir, cuando se peresneta una multiclase y no solo 2 de ellas. Este tió de funciones sirve para poder tranformar los logits en probabilidades y de esta forma poder realizar la clasificación, siendo la clase con la prbabilidad más alta a la que se le asiganrá esa clasificación.\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "\n",
    "Un ejemplo para esclarecer esto es si tenemos los logits y se nos presentan 3 clases a la cual puede hacxerse la clasificación.\n",
    "\n",
    "$$\n",
    "z_1 = 2.0, \\quad z_2 = 1.0, \\quad z_3 = -1.0\n",
    "$$\n",
    "\n",
    "Mediante el uso de Softmax, podemos calcular las probabilidades utilizando los logits.\n",
    "$$\n",
    "P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72\n",
    "$$\n",
    "$$\n",
    "P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26\n",
    "$$\n",
    "$$\n",
    "P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04\n",
    "$$\n",
    "\n",
    "Ante los resultados, podemos ver que la clase con la mayor probabilidad es la 1, por lo cual la clasificación será para la clase 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
