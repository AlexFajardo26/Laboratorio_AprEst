{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e32f0f2",
   "metadata": {},
   "source": [
    "## Apuntes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e671af3",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3f720",
   "metadata": {},
   "source": [
    "La regresión logística es un modelo de predicción y clasificación utilizado para poder hacer predicciones de resultados binarios, esto lo hace mediante la probabilidad de ocurrencia de un evento.\n",
    "\n",
    "Esto se calcula de la siguiente manera:\n",
    "\n",
    "$$\n",
    "z =\\beta^T X\n",
    "$$\n",
    "\n",
    "La probabilidad se calcula:\n",
    "\n",
    "$$\n",
    "p=\\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "Este modelo es utilizado debido a la sencillez que tiene para ser interpretado, ya que al tenr predicciones binarias, normalmente de 0 o 1, es más facil hacer un analisis e interpretación de estos resultados. Es importante mencionar que esto se logra calculando una probabilidad, que dependiendo del threshold que se tenga, es la clasificación que se dará en el modelo.\n",
    "\n",
    "### Función de Verosimilitud (regresion lineal)\n",
    "\n",
    "*Multiplicar probabilidades y se asume que siguen una distribucion normal*\n",
    "\n",
    "Dado un conjunto de datos $(X_i, y_i)$ con \\( i = 1, $\\dots$, m \\), la **función de verosimilitud** es:\n",
    "\n",
    "$$\n",
    "L(\\theta, \\sigma^2) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Tomamos el **logaritmo de la verosimilitud**:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta, \\sigma^2) = \\sum_{i=1}^{m} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "### **Relación con OLS**  \n",
    "\n",
    "Para **maximizar la verosimilitud respecto a $\\theta$ **, ignoramos términos constantes:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\sum_{i=1}^{m} -\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "Esto equivale a **minimizar el error cuadrático**:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{m} (y_i - \\theta^T X_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "**Conclusión:** Minimizar el error cuadrático con **OLS** es lo mismo que **maximizar la verosimilitud** bajo una **distribución normal de los errores**.\n",
    "\n",
    "\n",
    "### **Función de Verosimilitud (regresion logistica)**\n",
    "\n",
    "*Ahora $y_i$ sigue una distribución de Bernouilli*\n",
    "\n",
    "*$\\sigma$ es la función sigmoide*\n",
    "\n",
    "*La función de verosimilitud es la multiplicación de probabilidades*\n",
    "\n",
    "Como \\( y \\) sigue una **distribución de Bernoulli**, la función de verosimilitud es:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Tomamos el **logaritmo de la verosimilitud**:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "### Función de Pérdida\n",
    "Para estimar $\\theta$, **maximizamos la log-verosimilitud**. \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "### **Regresión Logística con ascenso en Gradiente**\n",
    "\n",
    "Queremos minimizar la función de pérdida:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "### **Algoritmo ascenso en Gradiente**\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\frac{\\partial J}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### **Gradiente**\n",
    "El gradiente con respecto a $\\theta_j$ es:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "### **Algoritmo del Descenso en Gradiente**\n",
    "1. **Inicializar** $\\theta$.\n",
    "2. **Repetir** hasta convergencia:\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "Donde $\\alpha$ es la **tasa de aprendizaje**.\n",
    "\n",
    "**Conclusión:**  \n",
    "El descenso en gradiente encuentra los valores óptimos de $\\theta$ iterativamente, ajustándolos en la dirección del gradiente para minimizar la función de pérdida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7904d1f",
   "metadata": {},
   "source": [
    "## Odds y Log Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e8234",
   "metadata": {},
   "source": [
    "Los odds son la probabilidad de ganar entre la probabilidad de perder. Un ejemplo es si mi equipo gana 1 a 4, el odd sería $\\frac{1}{4}$\n",
    "\n",
    "Para comprobar esto tenemos que la probabilidad de ganar esn este caso sería:\n",
    "\n",
    "$$\\frac{1}{1+4} = 0.2$$\n",
    "\n",
    "La probabilidad de perder sería:\n",
    "\n",
    "$$\\frac{1}{1+4} = 0.8$$\n",
    "\n",
    "Si dividimos la probabilidad de ganar entre la de perder obetenemos\n",
    "\n",
    "$$\\frac{0.2}{0.8} = \\frac{1}{4}$$\n",
    "\n",
    "Con lo cual se comprueba el concepto de odds.\n",
    "\n",
    "Si lo ponemos como formula general tenemos que odds $\\frac{p}{1-p}$ donde $p$ es la probabilidad de ganar (pase el evento) y $1-p$ la probabilidad de perder (no pase el evento).\n",
    "\n",
    "Como los odds no son datos tan estabilizados y sigien un comportamiento exponencial, se utiliza el logaritmo para estabilizarlos y hacerlos más lineales, de esta forma es mas facil poder usarlos en la regresión logística. La fórmula de esto sería $ln (\\frac{p}{1-p})$.\n",
    "\n",
    "\n",
    "p se calcula:\n",
    "\n",
    "$$\n",
    "p=\\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "donde p es la probabilidad de que la predicción sea 1 (Si el numero es mayor a 0.5 se considera 1)\n",
    "\n",
    "donde z(log odds) se calcula:\n",
    "\n",
    "$$\n",
    "z = \\beta^T X\n",
    "$$\n",
    "\n",
    "donde multiplicamos los coeficientes la regresión lógistica y X las características de una persona aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bb368",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eac200",
   "metadata": {},
   "source": [
    "Utilizamos la función Softmax cuando no solo se tiene dos clases como en la regresión logística. Es decir, este modelo es para cuando se tiene una multiclase. \n",
    "\n",
    "La función Softmax convierte los logits (salidas de la función lineal) en probabilidades:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "\n",
    "#### **Ejemplo Numérico**\n",
    "Si tenemos 3 clases y logits calculados como:\n",
    "$$\n",
    "z_1 = 2.0, \\quad z_2 = 1.0, \\quad z_3 = -1.0\n",
    "$$\n",
    "Aplicamos Softmax:\n",
    "$$\n",
    "P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72\n",
    "$$\n",
    "$$\n",
    "P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26\n",
    "$$\n",
    "$$\n",
    "P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04\n",
    "$$\n",
    "Esto indica que la clase 1 es la más probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992a9c7",
   "metadata": {},
   "source": [
    "## Analisis de discriminante lineal\n",
    "\n",
    "El **Análisis Discriminante Gaussiano** (GDA, por sus siglas en inglés) es un método de clasificación supervisada en el campo del aprendizaje automático y la estadística. Es un modelo probabilístico que asume que los datos de cada clase siguen una distribución normal (gaussiana) y utiliza esta suposición para estimar las probabilidades de pertenencia a cada clase.\n",
    "\n",
    "## Conceptos clave del GDA:\n",
    "\n",
    "1. **Distribución Gaussiana (Normal)**:\n",
    "   - El GDA asume que los datos de cada clase \\( k \\) se distribuyen según una distribución normal multivariada:\n",
    "     $$\n",
    "     P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "     $$\n",
    "     Donde:\n",
    "     - $\\mathbf{x}$ es el vector de características.\n",
    "     - $\\mu_k$ es el vector de medias de la clase \\( k \\).\n",
    "     - $\\Sigma_k$ es la matriz de covarianza de la clase \\( k \\).\n",
    "     - $\\Sigma_k|$ es el determinante de la matriz de covarianza.\n",
    "\n",
    "2. **Clases**:\n",
    "   - El GDA se utiliza para problemas de clasificación en los que las etiquetas $y$ son discretas (por ejemplo, clasificación binaria o multiclase).\n",
    "\n",
    "3. **Probabilidad a priori**:\n",
    "   - El modelo también estima la probabilidad a priori $P(y = k)$ de cada clase, que representa la proporción de datos que pertenecen a la clase $k$.\n",
    "\n",
    "4. **Regla de Bayes**:\n",
    "   - Para clasificar un nuevo punto $\\mathbf{x}$, el GDA utiliza la regla de Bayes para calcular la probabilidad posterior:\n",
    "     $$\n",
    "     P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "     $$\n",
    "     Donde $P(\\mathbf{x})$ es la evidencia (normalización constante).\n",
    "\n",
    "5. **Decisión de clasificación**:\n",
    "   - El punto $\\mathbf{x}$ se asigna a la clase $ k$ que maximiza la probabilidad posterior $P(y = k | \\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf27d5",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74e58a",
   "metadata": {},
   "source": [
    "Una red neuronal es un modelo donde se realizan diferentes transformaciones a los datos para poder realizar una predicción. La red neuronal tiene una entrada que son todos los datos, y de ahí vienen las capas donde se encuentran las neuronas. estas capas cuentan también con una función de activación independiente, es justo en esas capas donde se realizan las transofmraciones de los datos. Después de realizar todo este proceso llamada forward propagation, se obtienen un predicción. Tras llegar a esta predicción se realiza ahora un back propagation, usando el metodo de descenso em gradiente, donde la predicción ahora es la entrada de la red neuronal y se vuelve a realizar el mismo proceso hasta que se obtenga el mejor resultado posible. \n",
    "\n",
    "Para el proceso de la red neuronal, primero se hace un Forward propagation. Esto es que metes datos a la entrada de la red. Despues pasasn por las capas ocultas del modelo donde a los datos de entrada se les multiplica por pesos y se le suma un sesgo. Es imporrante mencionar que en cada capa los datos van sufriendo tranformaciones mediante las fucniones de activación. \n",
    "   - Cada capa calcula:\n",
    "     $$\n",
    "     z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}\n",
    "     $$\n",
    "     $$\n",
    "     a^{[l]} = g(z^{[l]})\n",
    "     $$\n",
    "     donde \\( g \\) es la función de activación.\n",
    "\n",
    "Trs repetir el prceso por cada capa oculta se llega al final de la red donde obtenemos nuestra predicción. \n",
    "\n",
    "Para poder obtener la mejor predicción óptima que nos beneficie en el uso de este modelo, usamos ahora el Backpropgations, donde el modelo que tenemos aprende y ajusta los datos de salida cada vez hasta obtener la mejor predicción. Esto se hace:\n",
    "2. **Cálculo del error en la capa de salida:**  \n",
    "   Se mide la diferencia entre la salida predicha $a^{[L]}$ y el valor real $y$. Por ejemplo, para una función de costo $J$ (como la entropía cruzada), se calcula:\n",
    "   $$\n",
    "   \\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})\n",
    "   $$\n",
    "   donde $g'(z^{[L]})$ es la derivada de la función de activación en la capa de salida y $\\odot$ denota la multiplicación elemento a elemento.\n",
    "\n",
    "3. **Propagación del error hacia atrás:**  \n",
    "   Para cada capa $l$ de $L-1$ hasta la primera capa oculta), se calcula:\n",
    "   $$\n",
    "   \\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "   $$\n",
    "   Esto permite distribuir el error calculado en la capa de salida a todas las neuronas de las capas anteriores, de manera que cada parámetro se ajuste en función de su contribución al error final.\n",
    "\n",
    "\n",
    "5. **Actualización de parámetros:**  \n",
    "   Con un factor de aprendizaje $\\alpha$ y calculando las derivadas praciales, se actualizan los parámetros:\n",
    "   $$\n",
    "   W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "   $$\n",
    "   $$\n",
    "   b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "   $$\n",
    "\n",
    "Este proceso es el que repite iterativamente hasta que el error sea muy poco y se obtenga la mejor predicción posible. \n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132a5bf",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23174614",
   "metadata": {},
   "source": [
    "Metrica para medir algo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
